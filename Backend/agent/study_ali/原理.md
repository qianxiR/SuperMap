当前实现采用“后端仅决策与下发指令，前端落地执行”的链路：前端在 ChatAssistant.vue 将用户输入连同稳定的 conversation_id 发送到后端 /agent/tool-chat，model 使用 qwen-max。后端 FastAPI 通过 init_chat_model('openai:qwen-max') 仅绑定一个 LangChain 工具 toggle_layer_visibility(layer_id:str, action:'show'|'hide'|'toggle')，并把该会话的图层操作历史（由 _conversation_layer_history[conversation_id] 维护）注入到系统消息中，模型在第一轮回复里产出 tool_calls，后端执行工具并返回规范化字符串 action:layer_id，同时把本次指令追加进该会话历史。前端接收响应后，解析 tool_calls 与 tool_result，当工具名为 toggle_layer_visibility 时，从参数中取出 layer_id/layer_name 与 action，派发全局事件 agent:toggleLayerVisibility 交由图层管理逻辑执行实际显隐切换（OpenLayers 层状态更新），并将自然语言回复展示在会话中。这样，LLM 负责识别“打开/隐藏/切换@图层名称”的意图并产出结构化调用，后端只做工具编排与记忆注入，真正的图层可见性变更完全在前端地图管理中完成并与现有主题/样式系统保持一致。